import { Subject } from '@prisma/client';
import OpenAI from 'openai';
import { prisma } from './prisma';

function getOpenAI(): { chat: { completions: { create: (args: any) => Promise<{ choices: { message: { content: string } }[] }> } } } {
  const apiKey = process.env.OPENAI_API_KEY;
  if (apiKey && apiKey.trim().length > 0) {
    const client = new OpenAI({ apiKey });
    // Adapter pour retourner une forme homog√®ne
    return {
      chat: {
        completions: {
          create: async (args: any) => {
            const res = await (client as any).chat.completions.create(args);
            return res;
          },
        },
      },
    } as any;
  }
  // Fallback s√ªr sans cl√©: renvoyer une r√©ponse simul√©e
  return {
    chat: {
      completions: {
        create: async (_args: any) => ({ choices: [{ message: { content: 'R√©ponse simul√©e.' } }] }),
      },
    },
  } as any;
}

// Syst√®me de prompt pour ARIA
const ARIA_SYSTEM_PROMPT = `Tu es ARIA, l'assistant IA p√©dagogique de Nexus R√©ussite, sp√©cialis√© dans l'accompagnement des lyc√©ens du syst√®me fran√ßais en Tunisie.

R√àGLES IMPORTANTES :
1. Tu ne r√©ponds QUE sur la mati√®re demand√©e par l'√©l√®ve.
2. Tes r√©ponses sont bas√©es sur la base de connaissances Nexus R√©ussite fournie dans le contexte.
3. Tu adaptes ton niveau au lyc√©e (Seconde, Premi√®re, Terminale).
4. Tu es bienveillant, encourageant et p√©dagogue.
5. Tu proposes toujours des exemples concrets et d√©taill√©s.
6. Si tu ne sais pas, tu le dis et sugg√®res de contacter un coach.

STYLE :
- Utilise un ton amical mais professionnel.
- Structure tes r√©ponses clairement avec des titres et des listes.
- Utilise des √©mojis avec parcimonie pour illustrer tes points.
- Propose des exercices ou des m√©thodes pratiques √† la fin de tes explications.

FORMAT SP√âCIFIQUE "FICHE DE COURS" :
Si un √©l√®ve demande une "fiche de cours", "r√©sum√© de cours", ou un sujet similaire, tu dois g√©n√©rer une r√©ponse particuli√®rement structur√©e. Utilise le format Markdown suivant :
- Un titre principal (ex: "# üìù Fiche de Cours : [Nom du Chapitre]").
- Des sections claires avec des sous-titres (ex: "## 1. Concepts Cl√©s", "## 2. Formules Essentielles", "## 3. Exemple Concret", "## 4. Exercice d'Application").
- Utilise des listes √† puces pour les d√©finitions.
- Encadre les formules math√©matiques avec des backticks simples pour le LaTeX en ligne (ex: \`\\( E = mc^2 \\)\`).
- Conclus toujours par un encouragement.

Tu repr√©sentes l'excellence de Nexus R√©ussite.`;

// Recherche dans la base de connaissances (RAG)
async function searchKnowledgeBase(query: string, subject: Subject, limit: number = 3) {
  // Pour le MVP, on fait une recherche textuelle simple
  // Plus tard, on impl√©mentera la recherche vectorielle avec pgvector

  const contents = await prisma.pedagogicalContent.findMany({
    where: {
      OR: [
        { title: { contains: query } },
        { content: { contains: query } }
      ]
    },
    take: limit,
    orderBy: { createdAt: 'desc' }
  });

  return contents;
}

// G√©n√©ration de r√©ponse ARIA
export async function generateAriaResponse(
  studentId: string,
  subject: Subject,
  message: string,
  conversationHistory: Array<{ role: string; content: string; }> = []
): Promise<string> {
  try {
    // Recherche dans la base de connaissances
    const knowledgeBase = await searchKnowledgeBase(message, subject);

    // Construction du contexte
    let context = '';
    if (knowledgeBase.length > 0) {
      context = '\n\nCONTEXTE NEXUS R√âUSSITE :\n';
      knowledgeBase.forEach((content, index) => {
        context += `${index + 1}. ${content.title}\n${content.content}\n\n`;
      });
    }

    // Construction des messages pour OpenAI
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      {
        role: 'system',
        content: ARIA_SYSTEM_PROMPT + context
      },
      ...conversationHistory.map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      })),
      {
        role: 'user',
        content: `Mati√®re : ${subject}\n\nQuestion : ${message}`
      }
    ];

    // Appel √† OpenAI
    const completion = await getOpenAI().chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages,
      max_tokens: 1000,
      temperature: 0.7
    });

    return completion.choices[0]?.message?.content || 'D√©sol√©, je n\'ai pas pu g√©n√©rer une r√©ponse.';

  } catch (error) {
    console.error('Erreur ARIA:', error);
    // Si c'est une erreur de permission, on la relance pour que l'API renvoie un statut d'erreur
    if (error instanceof OpenAI.APIError && error.status === 403) {
      throw error;
    }
    return 'Je rencontre une difficult√© technique. Veuillez r√©essayer ou contacter un coach.';
  }
}

// Sauvegarde d'une conversation ARIA
export async function saveAriaConversation(
  studentId: string,
  subject: Subject,
  userMessage: string,
  ariaResponse: string,
  conversationId?: string
) {
  let conversation;

  if (conversationId) {
    conversation = await prisma.ariaConversation.findUnique({
      where: { id: conversationId }
    });
  }

  if (!conversation) {
    conversation = await prisma.ariaConversation.create({
      data: {
        studentId,
        subject
      }
    });
  }

  // Sauvegarde du message utilisateur
  await prisma.ariaMessage.create({
    data: {
      conversationId: conversation.id,
      role: 'user',
      content: userMessage
    }
  });

  // Sauvegarde de la r√©ponse ARIA
  const ariaMessage = await prisma.ariaMessage.create({
    data: {
      conversationId: conversation.id,
      role: 'assistant',
      content: ariaResponse
    }
  });

  return { conversation, ariaMessage };
}

// Enregistrement du feedback utilisateur
export async function recordAriaFeedback(messageId: string, feedback: boolean) {
  return await prisma.ariaMessage.update({
    where: { id: messageId },
    data: { feedback }
  });
}
